{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T22:06:58.330718Z",
     "start_time": "2019-03-14T22:06:58.327017Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "tfe.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, config, batch, word_mat=None, char_mat=None, trainable=True, opt=True):\n",
    "    self.config = config\n",
    "    self.global_step = tf.get_variable('global_step', shape=[], dtype=tf.int32,\n",
    "                                       initializer=tf.constant_initializer(0), trainable=False)\n",
    "    # c: context; q: question; ch: context char; qh: question char; y1: start; y2: end\n",
    "    self.c, self.q, self.ch, self.qh, self.y1, self.y2, self.qa_id = batch.get_next()\n",
    "    self.is_train = tf.get_variable(\n",
    "        \"is_train\", shape=[], dtype=tf.bool, trainable=False)\n",
    "    # word embedding\n",
    "    self.word_mat = tf.get_variable(\"word_mat\", initializer=tf.constant(\n",
    "        word_mat, dtype=tf.float32), trainable=False)\n",
    "    # char embedding\n",
    "    self.char_mat = tf.get_variable(\n",
    "        \"char_mat\", initializer=tf.constant(char_mat, dtype=tf.float32))\n",
    "    # mask for padding, used in the pointer network\n",
    "    self.c_mask = tf.cast(self.c, tf.bool)\n",
    "    self.q_mask = tf.cast(self.q, tf.bool)\n",
    "    # actual word length for context in a batch\n",
    "    self.c_len = tf.reduce_sum(tf.cast(self.c_mask, tf.int32), axis=1)\n",
    "    self.q_len = tf.reduce_sum(tf.cast(self.q_mask, tf.int32), axis=1)\n",
    "\n",
    "    if opt:\n",
    "        N, CL = config.batch_size, config.char_limit\n",
    "        # max word length for context in a batch\n",
    "        self.c_maxlen = tf.reduce_max(self.c_len)\n",
    "        # max word lenght for question in a batch\n",
    "        self.q_maxlen = tf.reduce_max(self.q_len)\n",
    "        \n",
    "        # truncate at [bs, c_maxlen]\n",
    "        self.c = tf.slice(self.c, [0, 0], [N, self.c_maxlen])\n",
    "        # truncate at [bs, q_maxlen]\n",
    "        self.q = tf.slice(self.q, [0, 0], [N, self.q_maxlen])\n",
    "        \n",
    "        # truncate the mask\n",
    "        self.c_mask = tf.slice(self.c_mask, [0, 0], [N, self.c_maxlen])\n",
    "        self.q_mask = tf.slice(self.q_mask, [0, 0], [N, self.q_maxlen])\n",
    "        \n",
    "        # [bs, c_maxlen, char_limit]\n",
    "        self.ch = tf.slice(self.ch, [0, 0, 0], [N, self.c_maxlen, CL]) \n",
    "        # [bs, q_maxlen, char_limit]\n",
    "        self.qh = tf.slice(self.qh, [0, 0, 0], [N, self.q_maxlen, CL]) \n",
    "        \n",
    "        # y is one_hot encoded\n",
    "        # [batch_size, c_maxlen]\n",
    "        self.y1 = tf.slice(self.y1, [0, 0], [N, self.c_maxlen])\n",
    "        self.y2 = tf.slice(self.y2, [0, 0], [N, self.c_maxlen])\n",
    "    else:\n",
    "        self.c_maxlen, self.q_maxlen = config.para_limit, config.ques_limit\n",
    "    \n",
    "    # actual char length for context, reshape to 1D tensor\n",
    "    self.ch_len = tf.reshape(tf.reduce_sum(\n",
    "        tf.cast(tf.cast(self.ch, tf.bool), tf.int32), axis=2), [-1])\n",
    "    # actual char length for question, reshape to 1D tensor\n",
    "    self.qh_len = tf.reshape(tf.reduce_sum(\n",
    "        tf.cast(tf.cast(self.qh, tf.bool), tf.int32), axis=2), [-1])\n",
    "\n",
    "    self.ready()\n",
    "\n",
    "    if trainable:\n",
    "        self.lr = tf.get_variable(\n",
    "            \"lr\", shape=[], dtype=tf.float32, trainable=False)\n",
    "        self.opt = tf.train.AdadeltaOptimizer(\n",
    "            learning_rate=self.lr, epsilon=1e-6)\n",
    "        grads = self.opt.compute_gradients(self.loss)\n",
    "        gradients, variables = zip(*grads)\n",
    "        capped_grads, _ = tf.clip_by_global_norm(\n",
    "            gradients, config.grad_clip)\n",
    "        self.train_op = self.opt.apply_gradients(\n",
    "            zip(capped_grads, variables), global_step=self.global_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ready(self):\n",
    "    config = self.config\n",
    "    N, PL, QL, CL, d, dc, dg = config.batch_size, self.c_maxlen, self.q_maxlen, config.char_limit, config.hidden, config.char_dim, config.char_hidden\n",
    "    gru = cudnn_gru if config.use_cudnn else native_gru\n",
    "\n",
    "    with tf.variable_scope(\"emb\"):\n",
    "        # char embedding\n",
    "        with tf.variable_scope(\"char\"):\n",
    "            # char-embedding\n",
    "            ch_emb = tf.reshape(tf.nn.embedding_lookup(\n",
    "                self.char_mat, self.ch), [N * PL, CL, dc]) # [bs * self.c_maxlen, self.char_limit, self.char_emb_dim]\n",
    "            qh_emb = tf.reshape(tf.nn.embedding_lookup(\n",
    "                self.char_mat, self.qh), [N * QL, CL, dc]) # [bs * self.q_maxlen, self.char_limit, self.char_emb_dim]\n",
    "\n",
    "            # variational dropout\n",
    "            # same drouput mask for each timestep\n",
    "            ch_emb = dropout(\n",
    "                ch_emb, keep_prob=config.keep_prob, is_train=self.is_train)  # [bs * self.c_maxlen, self.char_limit, self.char_emb_dim]\n",
    "            qh_emb = dropout(\n",
    "                qh_emb, keep_prob=config.keep_prob, is_train=self.is_train)  # [bs * self.q_maxlen, self.char_limit, self.char_emb_dim]\n",
    "\n",
    "            # bi_gru for context\n",
    "            cell_fw = tf.contrib.rnn.GRUCell(dg)\n",
    "            cell_bw = tf.contrib.rnn.GRUCell(dg)\n",
    "            _, (state_fw, state_bw) = tf.nn.bidirectional_dynamic_rnn(\n",
    "                cell_fw, cell_bw, ch_emb, self.ch_len, dtype=tf.float32)\n",
    "            ch_emb = tf.concat([state_fw, state_bw], axis=1)\n",
    "\n",
    "            # bi_gru for question\n",
    "            _, (state_fw, state_bw) = tf.nn.bidirectional_dynamic_rnn(\n",
    "                cell_fw, cell_bw, qh_emb, self.qh_len, dtype=tf.float32)\n",
    "            qh_emb = tf.concat([state_fw, state_bw], axis=1)\n",
    "\n",
    "            qh_emb = tf.reshape(qh_emb, [N, QL, 2 * dg]) # [bs, q_maxlen, 2*char_hidden_size]\n",
    "            ch_emb = tf.reshape(ch_emb, [N, PL, 2 * dg]) # [bs, c_maxlen, 2*char_hidden_size]\n",
    "\n",
    "        # word embedding\n",
    "        with tf.name_scope(\"word\"):\n",
    "            c_emb = tf.nn.embedding_lookup(self.word_mat, self.c) # [bs, c_maxlen, word_emb_dim]\n",
    "            q_emb = tf.nn.embedding_lookup(self.word_mat, self.q) # [bs, q_maxlen, word_emb_dim]\n",
    "\n",
    "        # concat word and char embedding \n",
    "        c_emb = tf.concat([c_emb, ch_emb], axis=2) # [bs, c_maxlen, word_emb_dim + char_emb_dim]\n",
    "        q_emb = tf.concat([q_emb, qh_emb], axis=2) # [bs, q_maxlen, word_emb_dim + char_emb_dim]\n",
    "\n",
    "    # Q and C encoding\n",
    "    with tf.variable_scope(\"encoding\"):\n",
    "        rnn = gru(num_layers=3, num_units=d, batch_size=N, input_size=c_emb.get_shape(\n",
    "        ).as_list()[-1], keep_prob=config.keep_prob, is_train=self.is_train)\n",
    "        c = rnn(c_emb, seq_len=self.c_len) # [bs, c_maxlen, hidden_size]\n",
    "        q = rnn(q_emb, seq_len=self.q_len) # [bs, q_maxlen, hidden_size]\n",
    "\n",
    "    # C Q attention\n",
    "    with tf.variable_scope(\"attention\"):\n",
    "        qc_att = dot_attention(c, q, mask=self.q_mask, hidden=d,\n",
    "                               keep_prob=config.keep_prob, is_train=self.is_train) # [bs, c_maxlen, 2 * hidden_size]\n",
    "        rnn = gru(num_layers=1, num_units=d, batch_size=N, input_size=qc_att.get_shape(\n",
    "        ).as_list()[-1], keep_prob=config.keep_prob, is_train=self.is_train)\n",
    "        att = rnn(qc_att, seq_len=self.c_len) # [bs, c_maxlen, hidden_size]\n",
    "\n",
    "    # C C self attention\n",
    "    with tf.variable_scope(\"match\"):\n",
    "        self_att = dot_attention(\n",
    "            att, att, mask=self.c_mask, hidden=d, keep_prob=config.keep_prob, is_train=self.is_train) # [bs, c_maxlen, 2 * hidden_size]\n",
    "        rnn = gru(num_layers=1, num_units=d, batch_size=N, input_size=self_att.get_shape(\n",
    "        ).as_list()[-1], keep_prob=config.keep_prob, is_train=self.is_train)\n",
    "        match = rnn(self_att, seq_len=self.c_len)  # [bs, c_maxlen, hidden_size]\n",
    "\n",
    "    # pointer network\n",
    "    # logits 1: start position logits; logits 2: end position logits\n",
    "    with tf.variable_scope(\"pointer\"):\n",
    "        # self attention\n",
    "        init = summ(q[:, :, -2 * d:], d, mask=self.q_mask,\n",
    "                    keep_prob=config.ptr_keep_prob, is_train=self.is_train)\n",
    "        pointer = ptr_net(batch=N, hidden=init.get_shape().as_list(\n",
    "        )[-1], keep_prob=config.ptr_keep_prob, is_train=self.is_train)\n",
    "        logits1, logits2 = pointer(init, match, d, self.c_mask)\n",
    "\n",
    "    # compute loss\n",
    "    with tf.variable_scope(\"predict\"):\n",
    "        ##### for prediction\n",
    "        ##### During prediction, we choose the best span from token i to token i' such that i<=i'<=i+15 and p1*p2 is maximized.\n",
    "        # outer product: p1*p2\n",
    "        # tf.expand_dims(tf.nn.softmax(logits1), axis=2): [bs, c_maxlen, 1]\n",
    "        # tf.expand_dims(tf.nn.softmax(logits2), axis=1): [bs, 1, c_maxlen]\n",
    "        # outer: [bs, c_maxlen, c_maxlen]\n",
    "        outer = tf.matmul(tf.expand_dims(tf.nn.softmax(logits1), axis=2),\n",
    "                          tf.expand_dims(tf.nn.softmax(logits2), axis=1))  \n",
    "        \n",
    "        # slice [start:start+15]\n",
    "        outer = tf.matrix_band_part(outer, 0, 15)  # [bs, c_maxlen, 15]\n",
    "        \n",
    "        # yp1: start prob; yp2: end prob\n",
    "        self.yp1 = tf.argmax(tf.reduce_max(outer, axis=2), axis=1)\n",
    "        self.yp2 = tf.argmax(tf.reduce_max(outer, axis=1), axis=1)\n",
    "        \n",
    "        ##### for training: see below image\n",
    "        losses = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                            logits=logits1, labels=tf.stop_gradient(self.y1))  # padding are included in the loss\n",
    "        losses2 = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                            logits=logits2, labels=tf.stop_gradient(self.y2))  # padding are included in the loss\n",
    "        self.loss = tf.reduce_mean(losses + losses2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/loss_formula.png' width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T22:02:38.976311Z",
     "start_time": "2019-03-14T22:02:38.970175Z"
    }
   },
   "outputs": [],
   "source": [
    "c_maxlen = 3\n",
    "a = np.random.randint(0, 10, [3, 1])\n",
    "b = np.random.randint(0, 10, [1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T22:02:44.284918Z",
     "start_time": "2019-03-14T22:02:44.280383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [6],\n",
       "       [6]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T22:02:46.106869Z",
     "start_time": "2019-03-14T22:02:46.102719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 6, 2]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T22:02:49.110831Z",
     "start_time": "2019-03-14T22:02:49.106644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 30, 10],\n",
       "       [ 0, 36, 12],\n",
       "       [ 0, 36, 12]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T22:02:54.049047Z",
     "start_time": "2019-03-14T22:02:54.045067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 30, 10],\n",
       "       [ 0, 36, 12],\n",
       "       [ 0, 36, 12]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T22:08:47.625702Z",
     "start_time": "2019-03-14T22:08:47.620420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, 10,  4, 13,  3,  6,  8,  3, 10,  6,  5,  4,  7, 14, 11],\n",
       "       [10,  7, 17, 13, 13, 19, 16, 15, 15, 17, 17,  2,  6, 17, 16],\n",
       "       [ 6,  6,  7, 16, 17,  2, 19, 14,  7, 17, 12, 15,  0,  2, 16],\n",
       "       [ 3, 19,  7,  4,  6, 17,  9, 15, 12, 18,  4, 11, 16, 11,  5],\n",
       "       [ 8, 18, 11,  2,  3,  8, 13,  3,  6, 19,  9, 13,  2, 15, 18],\n",
       "       [14,  1,  4, 16, 10, 11, 17,  6, 16, 11,  6, 15,  6,  3,  2],\n",
       "       [16, 18,  9, 13,  5, 10,  4, 15, 15,  6,  2,  3,  6, 19, 18],\n",
       "       [ 9,  6,  0, 14, 14,  8,  1,  3, 14, 13, 12, 13, 14,  0, 13],\n",
       "       [ 2, 10,  1, 15,  1, 11, 13,  2,  3, 14,  4, 15,  9, 15, 19],\n",
       "       [19,  9,  3, 18,  6,  5, 13, 13, 19, 17,  7, 12,  4,  4,  9],\n",
       "       [16, 15, 10,  8, 12, 10, 15, 17,  2, 14, 19,  9,  3, 19,  9],\n",
       "       [15, 11,  6,  7,  0, 13,  7,  9,  6,  9, 16, 11, 18, 14,  9],\n",
       "       [13,  9,  6,  2,  7, 19,  2,  7,  2,  4,  3,  5,  1, 19,  7],\n",
       "       [ 2,  2,  6, 14,  0, 13,  6, 15, 17,  3,  9,  6,  5,  6, 10],\n",
       "       [ 3,  6,  6,  3, 11, 18, 11,  2, 10,  2, 17,  7,  7, 14,  2]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.random.randint(0,20,[15,15])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T22:08:49.876154Z",
     "start_time": "2019-03-14T22:08:49.871006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=12, shape=(15, 15), dtype=int64, numpy=\n",
       "array([[ 2, 10,  4, 13,  3,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  7, 17, 13, 13, 19, 16,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  7, 16, 17,  2, 19, 14,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  4,  6, 17,  9, 15, 12,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  3,  8, 13,  3,  6, 19,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 11, 17,  6, 16, 11,  6,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  4, 15, 15,  6,  2,  3,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  3, 14, 13, 12, 13, 14,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  3, 14,  4, 15,  9, 15,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 17,  7, 12,  4,  4,  9],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 19,  9,  3, 19,  9],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 11, 18, 14,  9],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 19,  7],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  6, 10],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2]])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matrix_band_part(c, 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(self):\n",
    "        return self.loss\n",
    "\n",
    "def get_global_step(self):\n",
    "    return self.global_step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
